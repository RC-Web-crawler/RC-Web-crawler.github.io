<!DOCTYPE html>
<html lang="en" class="js csstransforms3d">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="Hugo 0.91.2" />
    <meta name="description" content="">


    <link rel="icon" href="../../images/favicon.png" type="image/png">

    <title>Content Analysis : Web Crawler</title>

    
    <link href="../../css/nucleus.css?1661496936" rel="stylesheet">
    <link href="../../css/fontawesome-all.min.css?1661496936" rel="stylesheet">
    <link href="../../css/hybrid.css?1661496936" rel="stylesheet">
    <link href="../../css/featherlight.min.css?1661496936" rel="stylesheet">
    <link href="../../css/perfect-scrollbar.min.css?1661496936" rel="stylesheet">
    <link href="../../css/auto-complete.css?1661496936" rel="stylesheet">
    <link href="../../css/atom-one-dark-reasonable.css?1661496936" rel="stylesheet">
    <link href="../../css/theme.css?1661496936" rel="stylesheet">
    <link href="../../css/tabs.css?1661496936" rel="stylesheet">
    <link href="../../css/hugo-theme.css?1661496936" rel="stylesheet">
    
    <link href="../../css/theme-green.css?1661496936" rel="stylesheet">
    
    

    <script src="../../js/jquery-3.3.1.min.js?1661496936"></script>

    <style>
      :root #header + #content > #left > #rlblock_left{
          display:none !important;
      }
      
        :not(pre) > code + span.copy-to-clipboard {
            display: none;
        }
      
    </style>
    
  </head>
  <body class="" data-url="../../2nd_home/6_content/">
    <nav id="sidebar" class="">



  <div id="header-wrapper">
    <div id="header">
      <a id="logo" href="https://github.com/RC-Web-crawler/Hugo-site">
  <img src="../../images/web_crawler.png">
</a>
    </div>
    
        <div class="searchbox">
    <label for="search-by"><i class="fas fa-search"></i></label>
    <input data-search-input id="search-by" type="search" placeholder="Search...">
    <span data-search-clear=""><i class="fas fa-times"></i></span>
</div>

<script type="text/javascript" src="../../js/lunr.min.js?1661496936"></script>
<script type="text/javascript" src="../../js/auto-complete.js?1661496936"></script>
<script type="text/javascript">
    
        var baseurl = "https:\/\/rc-web-crawler.github.io\/";
    
</script>
<script type="text/javascript" src="../../js/search.js?1661496936"></script>

    
  </div>
  
    <section id="homelinks">
      <ul>
        <li>
            <a class="padding" href='../../'><i class='fas fa-home'></i> Home</a>
        </li>
      </ul>
    </section>
  

    <div class="highlightable">
    <ul class="topics">

        
          
          




 
  
    
    <li data-nav-id="/1st_home/" title="Web-Crawler" class="dd-item
        
        
        
        ">
      <a href="../../1st_home/">
          <b>1. </b>Web-Crawler
          
      </a>
      
      
        <ul>
          
          
          

        
          
            
            




 
  
    
      <li data-nav-id="/1st_home/1_web_at_glance/" title="1.1 Web at a glance" class="dd-item ">
        <a href="../../1st_home/1_web_at_glance/">
        1.1 Web at a glance
        
        </a>
    </li>
     
  
 

            
          
            
            




 
  
    
      <li data-nav-id="/1st_home/2_html_elements/" title="HTML elements &amp; Tree Structure" class="dd-item ">
        <a href="../../1st_home/2_html_elements/">
        1.2 HTML elements
        
        </a>
    </li>
     
  
 

            
          
            
            




 
  
    
      <li data-nav-id="/1st_home/3_css/" title="CSS selector &amp; Xpath" class="dd-item ">
        <a href="../../1st_home/3_css/">
        1.3 CSS selector &amp; Xpath
        
        </a>
    </li>
     
  
 

            
          
            
            




 
  
    
      <li data-nav-id="/1st_home/4_demo/" title="Demo: Web Scraping with R/Python" class="dd-item ">
        <a href="../../1st_home/4_demo/">
        1.4 Demo: with R &amp; Python
        
        </a>
    </li>
     
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
          




 
  
    
    <li data-nav-id="/2nd_home/" title="Content Analysis" class="dd-item
        parent
        
        
        ">
      <a href="../../2nd_home/">
          <b>2. </b>Content Analysis
          
      </a>
      
      
        <ul>
          
          
          

        
          
            
            




 
  
    
      <li data-nav-id="/2nd_home/5_keyword/" title="Keyword Analysis" class="dd-item ">
        <a href="../../2nd_home/5_keyword/">
        2.1 Keyword Analysis
        
        </a>
    </li>
     
  
 

            
          
            
            




 
  
    
      <li data-nav-id="/2nd_home/6_content/" title="Content Analysis" class="dd-item active">
        <a href="../../2nd_home/6_content/">
        2.2 Content Analysis
        
        </a>
    </li>
     
  
 

            
          
            
            




 
  
    
      <li data-nav-id="/2nd_home/7_shiny/" title="eCRF Index Shiny App" class="dd-item ">
        <a href="../../2nd_home/7_shiny/">
        2.3 eCRF Index Shiny App
        
        </a>
    </li>
     
  
 

            
          
        
        </ul>
      
    </li>
  
 

          
        
    </ul>

    
    
      <section id="shortcuts">
        <h3>More</h3>
        <ul>
          
              <li>
                  <a class="padding" href="https://github.com/RC-Web-crawler/Hugo-site"><i class='fab fa-fw fa-github'></i> GitHub</a>
              </li>
          
              <li>
                  <a class="padding" href="https://rc-web-crawler.github.io/credits"><i class='fas fa-fw fa-bullhorn'></i> Credits</a>
              </li>
          
        </ul>
      </section>
    

    
    <section id="footer">
      <p><a id="logo" href="https://github.com/RC-Web-crawler/Hugo-site">
  <img src="../../images/novartis-logo.png">
</a>Built with <i class="fas fa-heart"></i>
<a> from Web Crawler study group</a> and
<a href="https://gohugo.io/">Hugo</a></p>

    </section>
  </div>
</nav>




        <section id="body">
        <div id="overlay"></div>
        <div class="padding highlightable">
              
              <div>
                <div id="top-bar">
                
                
                <div id="breadcrumbs" itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb">
                    <span id="sidebar-toggle-span">
                        <a href="#" id="sidebar-toggle" data-sidebar-toggle="">
                          <i class="fas fa-bars"></i>
                        </a>
                    </span>
                  
                  <span id="toc-menu"><i class="fas fa-list-alt"></i></span>
                  
                  <span class="links">
                 
                 
                   Content Analysis
                 
                  </span>
                </div>
                
                    <div class="progress">
    <div class="wrapper">
<nav id="TableOfContents">
  <ul>
    <li><a href="#title-analysis-keyword-prediction">Title Analysis: Keyword Prediction</a></li>
    <li><a href="#pre-prepare-include-packages-and-source-data">Pre-prepare: Include packages and source data</a></li>
    <li><a href="#pre-prepare-including-data-and-building-dictonary">Pre-prepare: Including data and building dictonary</a></li>
    <li><a href="#keyword-cleaning">Keyword Cleaning</a></li>
    <li><a href="#keyword-imputation">Keyword Imputation</a></li>
    <li><a href="#keyword-prediction">Keyword Prediction</a></li>
    <li><a href="#further-explorations-and-conclusion">Further Explorations and conclusion</a></li>
  </ul>
</nav>
    </div>
</div>

                
              </div>
            </div>
            
        <div id="head-tags">
        
        </div>
        
        <div id="body-inner">
          
            <h1>
              
              Content Analysis
            </h1>
          

        


<h2 id="title-analysis-keyword-prediction">Title Analysis: Keyword Prediction</h2>
<p>Although most of the articles have keywords with them, there are still
quite a lot of articles without keywords. Meanwhile, some articles may
have complicated keywords, which could also increase the difficulty of
analysis. To solve this problem, we can try to predict the keywords with
title analysis techniques.</p>
<p>In the following parts, the keyword prediction using the results from
previous keyword analysis will be demonstrated.</p>
<h2 id="pre-prepare-include-packages-and-source-data">Pre-prepare: Include packages and source data</h2>
<p>We will mainly use the package <a href="https://quanteda.io/">quanteda</a> for our
analysis. Quanteda is an R package for managing and analyzing textual
data. It is designed for R users needing to apply natural language
processing to texts, from documents to final analysis.<br>

<div class="expand">
    <div class="expand-label" style="cursor: pointer;" onclick="$h = $(this);$h.next('div').slideToggle(100,function () {$h.children('i').attr('class',function () {return $h.next('div').is(':visible') ? 'fas fa-chevron-down' : 'fas fa-chevron-right';});});">
        <i style="font-size:x-small;" class="fas fa-chevron-right"></i>
        <span>
        
    	
    	package loading
    	
    	</span>
    </div>
    <div class="expand-content" style="display: none;">
        <pre><code>library(tidyverse)
library(tidytext)
library(dplyr)
library(XML)
library(knitr)
library(tm)
library(corpus)
library(quanteda)
library(readxl)
library(topicmodels)
library(textstem)

rm(list = ls())

set.seed(1234)
#Load data
paper &lt;- read_excel(&quot;~/tm/app-1/new_kw.xlsx&quot;)
</code></pre>

    </div>
</div></p>
<h2 id="pre-prepare-including-data-and-building-dictonary">Pre-prepare: Including data and building dictonary</h2>
<p>In our analysis, we will use topic-specific dictionaries. Topic-specific
dictionaries is a method somehow similar to <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment
analysis</a>. Its aim is
to determine the polarity of a text, which could be done by counting
terms that were previously assigned to the given categories. With this
method, we can categorize the given titles into specific keywords in our
dictionary.</p>
<p>To use topic-specific dictionaries, the keyword corpus and dictionary
need to be built in advance.<br>

<div class="expand">
    <div class="expand-label" style="cursor: pointer;" onclick="$h = $(this);$h.next('div').slideToggle(100,function () {$h.children('i').attr('class',function () {return $h.next('div').is(':visible') ? 'fas fa-chevron-down' : 'fas fa-chevron-right';});});">
        <i style="font-size:x-small;" class="fas fa-chevron-right"></i>
        <span>
        
    	
    	build dictionary
    	
    	</span>
    </div>
    <div class="expand-content" style="display: none;">
        <pre><code>#Build keyword corpus
paper2 &lt;- paper %&gt;%
  select(title, keyword) %&gt;%
  mutate(keyword2 = lemmatize_strings(str_to_lower(keyword))) 
corp_k &lt;- corpus(paper2, text_field = 'keyword2')
token_k &lt;- quanteda::tokens(corp_k, remove_numbers = TRUE, remove_punct = TRUE, remove_symbols = TRUE)

#Build dictionary based on keyword analysis result
dict &lt;- list(
  output_delivery_system = c('output','delivery','system'),
  hash_object = c('hash','object'),
  machine_learing = c('machine','learing'),
  dictionary_table = c('dictionary','table'),
  cdisc = c('cdisc','adam','sdtm','xml','domain','send'),
  multisheet_workbook = c('multi','sheet','workbook','excel'),
  business_intelligence = c('business','intelligence'),
  call_execute = c('call','execute'),
  repeated_measures = c('repeat','measures'),
  tagset = c('excelxp', 'tageset'),
  logistic_regression = c('logistic', 'regression'),
  time_series = c('time','series'),
  sas_af = c('sas','af'),
  sas_viya = c('sas','viya'),
  sas_internet = c('sas','internet'),
  sas_base = c('sas','base'),
  sas_graph = c('sas', 'visual', 'analytics','graph'),
  sas_consult = c('sas', 'consult', 'consultant'),
  sas_enterprise = c('sas', 'enterprise','guide','miner'),
  ods = c('ods','rtf','graphics','microsoft','od'),
  macro = c('macro'),
  array = c('array'),
  healthcare = c('healthcare'),
  format = c('format'),
  html = c('html'),
  global_forum = c('global','forum'),
  proc_sql = c('proc','sql'),
  proc_report = c('proc','report'),
  proc_template = c('proc','template','sasgf'),
  proc_tabulate = c('proc','tabulate'),
  clinical_trial = c('clinical','trial'),
  survival_analysis = c('survival','analysis'),
  data_warehouse = c('datum','warehouse'),
  data_mining = c('datum','mining'),
  data_management = c('datum','management'),
  data_integration = c('datum','integration'),
  data_quality = c('datum','quality','clean'),
  data_visualization = c('datum','visualization'),
  project_management = c('project','management')
)

lexicon &lt;- dictionary(dict)
</code></pre>

    </div>
</div></p>
<h2 id="keyword-cleaning">Keyword Cleaning</h2>
<p>We will calculate the keyword coverage from source data first. In this
study, the keyword coverage is defined as the percent of papers with any
keyword existing after imputation. Keyword cleaning is performed before
the calculation.<br>

<div class="expand">
    <div class="expand-label" style="cursor: pointer;" onclick="$h = $(this);$h.next('div').slideToggle(100,function () {$h.children('i').attr('class',function () {return $h.next('div').is(':visible') ? 'fas fa-chevron-down' : 'fas fa-chevron-right';});});">
        <i style="font-size:x-small;" class="fas fa-chevron-right"></i>
        <span>
        
    	
    	keyword cleaning
    	
    	</span>
    </div>
    <div class="expand-content" style="display: none;">
        <pre><code>#Clean Keyword
dfm_k &lt;- dfm(token_k) %&gt;% 
  dfm_remove(c(stopwords(&quot;english&quot;),'â','sas','datum')) %&gt;%
  dfm_group(groups = docvars(token_k)[,&quot;title&quot;]) %&gt;%
  dfm_lookup(dictionary = lexicon) 

dfm.prop.k &lt;- dfm_weight(dfm_k, scheme = &quot;prop&quot;)
df.prop.k &lt;- convert(dfm.prop.k, &quot;data.frame&quot;)

ncol_k &lt;- ncol(df.prop.k)

for (i in 1:nrow(df.prop.k)){
  df.prop.k[i,'max'] &lt;- max(df.prop.k[i,c(seq(2, ncol_k))])
  df.prop.k[i,'keyword_cleaned'] &lt;- ''
  
  for (j in 2:ncol_k){
    if (df.prop.k[i, j] == df.prop.k[i,'max'] &amp; df.prop.k[i,'max'] != 0){
      df.prop.k[i,'keyword_cleaned'] &lt;- paste(df.prop.k[i,'keyword_cleaned'], colnames(df.prop.k)[j])
    }
  }
}

#cleaned keyword coverage
paper3 &lt;- paper2 %&gt;%
  inner_join(df.prop.k, by=c('title' = 'doc_id')) %&gt;%
  select(title, keyword2, keyword_cleaned) %&gt;%
  mutate(null = ifelse(keyword_cleaned == '' &amp; grepl('kb', keyword2), 'Y', 'N'),
         coverage = ifelse(keyword_cleaned == &quot;&quot;, &quot;N&quot;, &quot;Y&quot;)) %&gt;%
  filter(null == 'N')

fail &lt;- paper3 %&gt;% 
  filter(coverage == 'N') %&gt;%
  group_by(keyword2) %&gt;%
  summarise(n = n()) %&gt;%
  arrange(desc(n))

cov_clean &lt;- paper3 %&gt;%
  group_by(coverage) %&gt;%
  summarise(n = n()) %&gt;%
  ungroup() %&gt;%
  mutate(percentage = round(n/sum(n)*100,2)) %&gt;%
  mutate(lab1=paste(coverage , n,sep=':'))#Coverage:73.18% of 13072

ggplot(cov_clean, aes(x='',y=n,fill=lab1)) +
  geom_bar (stat=&quot;identity&quot;, width=1) + 
  coord_polar (&quot;y&quot;, start=0) +
  geom_text(aes(label = paste0(percentage, &quot;%&quot;)), position = position_stack(vjust=0.5))+
  labs(x = NULL, y = NULL, fill = NULL,title=&quot;Coverage of cleaned keywords&quot;) + 
  theme_classic() +
  theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank()
        ) +
  scale_fill_brewer(palette=&quot;Blues&quot;)
</code></pre>

    </div>
</div><br>
<img src="https://raw.githubusercontent.com/RC-Web-crawler/Hugo-site/main/content/2nd_home/cov1-1.png"></p>
<p>Approximately 73.18% of the papers have cleaned keyword coverage.</p>
<h2 id="keyword-imputation">Keyword Imputation</h2>
<p>Next, we will use our dictionary to impute the keyword from the titles.
Similarly, the coverage of the imputed keyword will be calculated. Also,
we will calculate the accuracy of the imputation by comparing the
imputed results with cleaning results. The accuracy here is defined as
the percentage of papers where the cleaned keywords exist in the imputed
keywords for all the papers imputed.<br>

<div class="expand">
    <div class="expand-label" style="cursor: pointer;" onclick="$h = $(this);$h.next('div').slideToggle(100,function () {$h.children('i').attr('class',function () {return $h.next('div').is(':visible') ? 'fas fa-chevron-down' : 'fas fa-chevron-right';});});">
        <i style="font-size:x-small;" class="fas fa-chevron-right"></i>
        <span>
        
    	
    	keyword imputation
    	
    	</span>
    </div>
    <div class="expand-content" style="display: none;">
        <pre><code>#Build title corpus
paper4 &lt;- paper3 %&gt;% 
  filter(coverage == 'Y') %&gt;%
  mutate(title2 = lemmatize_strings(str_to_lower(title))) 

corp_t &lt;- corpus(paper4, text_field = 'title2')
token_t &lt;- quanteda::tokens(corp_t, remove_numbers = TRUE, remove_punct = TRUE, remove_symbols = TRUE)

#Impute Keyword
dfm_t &lt;- dfm(token_t) %&gt;% 
  dfm_remove(c(stopwords(&quot;english&quot;),'â','sas','datum')) %&gt;%
  dfm_group(groups = docvars(token_t)[,&quot;title&quot;]) %&gt;%
  dfm_lookup(dictionary = lexicon) 

dfm.prop.t &lt;- dfm_weight(dfm_t, scheme = &quot;prop&quot;)
df.prop.t &lt;- convert(dfm.prop.t, &quot;data.frame&quot;)

ncol_t &lt;- ncol(df.prop.t)

for (i in 1:nrow(df.prop.t)){
  df.prop.t[i,'max'] &lt;- max(df.prop.t[i,c(seq(2, ncol_t))])
  df.prop.t[i,'keyword_imputed'] &lt;- ''
  
  for (j in 2:ncol_t){
    if (df.prop.t[i, j] == df.prop.t[i,'max'] &amp; df.prop.t[i,'max'] != 0){
      df.prop.t[i,'keyword_imputed'] &lt;- paste(df.prop.t[i,'keyword_imputed'], colnames(df.prop.t)[j])
    }
  }
}

#imputed keyword coverage
paper5 &lt;- paper4 %&gt;%
  inner_join(df.prop.t, by=c('title' = 'doc_id')) %&gt;%
  select(title, keyword_cleaned, keyword_imputed) %&gt;%
  mutate(coverage = ifelse(keyword_imputed == &quot;&quot;, &quot;N&quot;, &quot;Y&quot;)) 

cov_imp &lt;- paper5 %&gt;%
  group_by(coverage) %&gt;%
  summarise(n = n()) %&gt;%
  ungroup() %&gt;%
  mutate(percentage = round(n/sum(n)*100,2)) %&gt;%
  mutate(lab1=paste(coverage , n,sep=':'))#Coverage:73.18% of 13072

ggplot(cov_imp, aes(x='',y=n,fill=lab1)) +
  geom_bar (stat=&quot;identity&quot;, width=1) + 
  coord_polar (&quot;y&quot;, start=0) +
  geom_text(aes(label = paste0(percentage, &quot;%&quot;)), position = position_stack(vjust=0.5))+
  labs(x = NULL, y = NULL, fill = NULL, title=&quot;Coverage of imputed keywords&quot;) + 
  theme_classic() +
  theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank()
        ) +
  scale_fill_brewer(palette=&quot;Blues&quot;)



#imputed keyword accuracy 
test &lt;- paper5 %&gt;%
  filter(coverage == 'Y') %&gt;%
  mutate(result = keyword_cleaned %in% keyword_imputed,
         success = sum(result))

cov_acc &lt;- test %&gt;%
  group_by(coverage) %&gt;%
  summarise(n = n()) %&gt;%
  ungroup() %&gt;%
  mutate(percentage = round(n/sum(n)*100,2)) %&gt;%
  mutate(lab1=paste(coverage , n,sep=':'))

ggplot(cov_acc, aes(x='',y=n,fill=lab1)) +
  geom_bar (stat=&quot;identity&quot;, width=1) + 
  coord_polar (&quot;y&quot;, start=0) +
  geom_text(aes(label = paste0(percentage, &quot;%&quot;)), position = position_stack(vjust=0.5))+
  labs(x = NULL, y = NULL, fill = NULL,title=&quot;Percent of imputed keywords that exist in cleaned keywords&quot;) + 
  theme_classic() +
  theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank()
        ) +
  scale_fill_manual(values='#71A92C')
</code></pre>

    </div>
</div><br>
<img src="https://raw.githubusercontent.com/RC-Web-crawler/Hugo-site/main/content/2nd_home/cov2-1.png">
<img src="https://raw.githubusercontent.com/RC-Web-crawler/Hugo-site/main/content/2nd_home/cov2-2.png">
Approximately 82.1% of the papers have keyword coverage after
imputation. Also, we can find that all the imputed keywords are within
cleaned keywords.</p>
<h2 id="keyword-prediction">Keyword Prediction</h2>
<p>Finally, we try to use the dictionary to predict the keyword of all the
papers we collected.<br>

<div class="expand">
    <div class="expand-label" style="cursor: pointer;" onclick="$h = $(this);$h.next('div').slideToggle(100,function () {$h.children('i').attr('class',function () {return $h.next('div').is(':visible') ? 'fas fa-chevron-down' : 'fas fa-chevron-right';});});">
        <i style="font-size:x-small;" class="fas fa-chevron-right"></i>
        <span>
        
    	
    	keyword prediction
    	
    	</span>
    </div>
    <div class="expand-content" style="display: none;">
        <pre><code>#Prediction
paper_all &lt;- read_excel(&quot;paper.xlsx&quot;)
paper_pred &lt;- paper_all %&gt;% 
  anti_join(paper5, by = 'title') %&gt;%
  mutate(title2 = lemmatize_strings(str_to_lower(title))) 

corp_p &lt;- corpus(paper_pred, text_field = 'title2')
token_p &lt;- quanteda::tokens(corp_p, remove_numbers = TRUE, remove_punct = TRUE, remove_symbols = TRUE)

#Predict Keyword
dfm_p &lt;- dfm(token_p) %&gt;% 
  dfm_remove(c(stopwords(&quot;english&quot;),'â','sas','datum')) %&gt;%
  dfm_group(groups = docvars(token_p)[,&quot;title&quot;]) %&gt;%
  dfm_lookup(dictionary = lexicon) 

dfm.prop.p &lt;- dfm_weight(dfm_p, scheme = &quot;prop&quot;)
df.prop.p &lt;- convert(dfm.prop.p, &quot;data.frame&quot;)

ncol_p &lt;- ncol(df.prop.p)

for (i in 1:nrow(df.prop.p)){
  df.prop.p[i,'max'] &lt;- max(df.prop.p[i,c(seq(2, ncol_p))])
  df.prop.p[i,'keyword_predict'] &lt;- ''
  
  for (j in 2:ncol_p){
    if (df.prop.p[i, j] == df.prop.p[i,'max'] &amp; df.prop.p[i,'max'] != 0){
      df.prop.p[i,'keyword_predict'] &lt;- paste(df.prop.p[i,'keyword_predict'], colnames(df.prop.p)[j])
    }
  }
}

#predict keyword coverage
paper_pred &lt;- paper_pred %&gt;%
  inner_join(df.prop.p, by=c('title' = 'doc_id')) %&gt;%
  mutate(coverage = ifelse(keyword_predict == &quot;&quot;, &quot;N&quot;, &quot;Y&quot;)) 

cov_pred &lt;- paper_pred %&gt;%
  group_by(coverage) %&gt;%
  summarise(n = n()) %&gt;%
  ungroup() %&gt;%
  mutate(percentage = round(n/sum(n)*100,2)) %&gt;%
  mutate(lab1=paste(coverage , n,sep=':'))#Coverage:73.18% of 13072

ggplot(cov_pred, aes(x='',y=n,fill=lab1)) +
  geom_bar (stat=&quot;identity&quot;, width=1) + 
  coord_polar (&quot;y&quot;, start=0) +
  geom_text(aes(label = paste0(percentage, &quot;%&quot;)), position = position_stack(vjust=0.5))+
  labs(x = NULL, y = NULL, fill = NULL,title=&quot;Coverage of predicted keywords for all papers&quot;) + 
  theme_classic() +
  theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank()
        ) +
  scale_fill_brewer(palette=&quot;Blues&quot;)
</code></pre>

    </div>
</div><br>
<img src="https://raw.githubusercontent.com/RC-Web-crawler/Hugo-site/main/content/2nd_home/pred-1.png"></p>
<p>After predicting keywords using our dictionary model, the predicted
keyword coverage of all the papers is approximately 53.16%.</p>
<h2 id="further-explorations-and-conclusion">Further Explorations and conclusion</h2>
<p>Our exploration indicates that dictionary model could be useful when
keywords are not presented. After prediction with the model, the
keywords of more than half of the papers could be imputed. Moreover, the
dictionary used in our study is relatively crude. With a better
dictionary, the coverage could be even higher.<br>
Besides, we also tried to use <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet
Allocation(LDA)</a>
to perform a topic modeling analysis. However, because the number of
words in a title is relatively small, we did not get a satisfying
result.</p>
<p>Other methods may also be applied in the topic analysis, such as
supervised machine learning. If you are interested, have a try!</p>


<footer class="footline">
	
</footer>

        
        </div>
        

      </div>

    <div id="navigation">
        
        

        
            
            
                
                    
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
            
        

        


	 
	 
		
			<a class="nav nav-prev" href="../../2nd_home/5_keyword/" title="Keyword Analysis"> <i class="fa fa-chevron-left"></i></a>
		
		
			<a class="nav nav-next" href="../../2nd_home/7_shiny/" title="eCRF Index Shiny App" style="margin-right: 0px;"><i class="fa fa-chevron-right"></i></a>
		
	
    </div>

    </section>

    <div style="left: -1000px; overflow: scroll; position: absolute; top: -1000px; border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;">
      <div style="border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;"></div>
    </div>
    <script src="../../js/clipboard.min.js?1661496936"></script>
    <script src="../../js/perfect-scrollbar.min.js?1661496936"></script>
    <script src="../../js/perfect-scrollbar.jquery.min.js?1661496936"></script>
    <script src="../../js/jquery.sticky.js?1661496936"></script>
    <script src="../../js/featherlight.min.js?1661496936"></script>
    <script src="../../js/highlight.pack.js?1661496936"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="../../js/modernizr.custom-3.6.0.js?1661496936"></script>
    <script src="../../js/learn.js?1661496936"></script>
    <script src="../../js/hugo-learn.js?1661496936"></script>
    
        
            <script src="../../mermaid/mermaid.js?1661496936"></script>
        
        <script>
            mermaid.initialize({ startOnLoad: true });
        </script>
    
    

  </body>
</html>

